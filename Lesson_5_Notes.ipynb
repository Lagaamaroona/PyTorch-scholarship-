{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 5 notes: convelutional neural networks\n",
    "\n",
    "Convelutional neural networks are a different type of networks, useful for:\n",
    "1. Voice User Interface: Wavenet\n",
    "2. Natural Language Processing\n",
    "3. Computer Vision \n",
    "\n",
    "\n",
    "\n",
    "## Features: \n",
    "The shapes and colors that define an image. Part of the job of a CNN is to identify the features in order to detect patterns in an image, such as edges.\n",
    "\n",
    "For example, in the case of a dog image the features can be the size, shape, legs, and so on. \n",
    "\n",
    "What makes up an image is the **features** of an image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Computers Interpret Data\n",
    "\n",
    "1. **Grayscale image:** a grid of values, maid up of pixels with numerical values. \n",
    "2. **Pre-process data:** Making each pixel between 0 and 1 instead of 0 to 255 (normalization). This helps the algorithm work better when detecting features. \n",
    "3. **MLP**: Multi-layer Perceptron, the method learned in the previous lesson takes vector as input such that a 28 by 28 images will simply be a vector of 784 units. \n",
    "4. **Flattening**: The process of converting an image to a vector, row 1 is first part, row 2 is second part, etc..\n",
    "\n",
    "\n",
    "Keep in mind that although flattenning is used in MLP, this strategy is not perfect because the network doesn't learn based on which pixels are next to each and with real world data an MLP is not the best choice.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptions\n",
    "\n",
    "Multi-Layer Perceptions(MLP) are the networks we have been construcing during lesson 4. This networks consist of fully connected layers starting from input layers to hidden layers and finally to an output layers. \n",
    "\n",
    "The task of classifying image in an MLP is a multi-process step. \n",
    "1. First, Visualize the data set to understand input size and the task. \n",
    "2. Normalize data, applying any transformations required such as converting to a tensor. \n",
    "3. Define a model and a pre-trained network. \n",
    "4. Train the model\n",
    "5. Test the model \n",
    "\n",
    "Next, it's time to start working convulutional neural networks which are another way of working with images. \n",
    "\n",
    "**Important Definitions**:\n",
    "1. **Class Score**: The output of the network, Indicates how sure a network is that a given input is of a specific task. \n",
    "2. **Loss**: Measure any difference from a predicted and a true class\n",
    "3. **Backrpopagation**: Quatify how bad a particular weight is in making a mistake\n",
    "4. **Optimization**: Gives us a way to calculate a better weight value\n",
    "5. **Cross-Entropy Loss**: Looks at the label's probability value and takes the negative Loss log of that value. The loss is lower when the loss and prediction agree. \n",
    "6. **Types of optimizers**: See code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Note that the best optimizers are SGD and Adam because they are combinations of the other optimizers'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam = optim.Adagrad(model.parameters(), lr=0.001)\n",
    "adadelta = optim.Adadelta(model.parameters(), lr=0.001)\n",
    "SGD = optim.SGD(model.parameters(), lr=0.001)\n",
    "rmsProp = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "Adadelta = optim.Adadelta(model.parameters(), lr=0.001)\n",
    "\n",
    "\"\"\" Note that the best optimizers are SGD and Adam because they are combinations of the other optimizers\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks \n",
    "\n",
    "\n",
    "Convolutional Neural Networks are a different type of network, much better for real-world data where the actual image may be anywhere around the large image. Some reason of this include:\n",
    "\n",
    "1. MLPs are flatten the data, converting it into a vector. Due to this, MLPS and are not aware what the initial image looks like and they can't understand the relationship between a pixel and the pixel above it. \n",
    "2. In comparison, CNN understand that pixels closer to each other are more related by accepting matrices as input. \n",
    "3. MLPs only use fully connected layers, where CNNs use sparsely connected layers. This means that the CNN doesn't immediately look at whole image, but it looks at parts of the image in order to make up the bigger picture. \n",
    "4. In a CNN every hidden layer recieves a part of the data the previous layer had. \n",
    "\n",
    "\n",
    "Basically, in any case where data is laid in a more complciated arichtecture such that the data can be anywhere in the images instead of simply in the center, a CNN has a serious advantage. \n",
    "\n",
    "\n",
    "## Filters\n",
    "\n",
    "A filters is a way to extract information from the image such as the edges, represented by a gram matrix. This gram matrix is multiplied by part of the image to generate a convoluted output. \n",
    "\n",
    "**Intensity** is the measure of brightness, intensity can be used to detect the shape for tasks like distinguishing boundries between people and background. \n",
    "\n",
    "**Frequency** is the rate of change whhere high frequency means a high change in colors and low frequency is simply a low or no change. For example, in an image of person with white background the person outline would have high frequency. \n",
    "\n",
    "**High-Pass Filter** is the process of emphasizing edges and darking out areas where the roc is low and changing images where the roc is high to white. \n",
    "\n",
    "**Convolution Kernels**: Taking a kernel and passing it through an image\n",
    "\n",
    "The process of using a high pass filter involves taking a kernel, and multiplying it by each set of pixels in the images. A high value indicates an edge. However, what happens when you get to the edges of the image? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layer\n",
    "\n",
    "* A stack of feature maps - one feature map for each filter \n",
    "* Produced by applying a series of different images filters, aka convolutionals kernels. \n",
    "* The amount of kernels equals the amount of images produced \n",
    "\n",
    "\n",
    "**Hyperparameters:**\n",
    "\n",
    "* Increasing the number of filters increases the number of nodes.\n",
    "* Increase size of each filter increases the size of the patterns\n",
    "* Stride: The amount by which the filter slides over the window.\n",
    "\n",
    "\n",
    "One possible issue with the convolutional layer is dealing with the nodes outside of the image. Solutions include:\n",
    "1. Ignoring them - this might cause an issue of the edges being undefined\n",
    "2. Pad the image with 0 to give the filter more space to move. \n",
    "\n",
    "\n",
    "**Define a convolutional layer:**\n",
    "\n",
    "1. Define the layers of the model in the `__init__` function\n",
    "2. Use `super(Net, self).__init__()` just like in an MLP \n",
    "3. Initialize the height and width based on the filter value\n",
    "4. Set self.conv `nn.Conv(1, gray_scalefilters, kernel_size, bias)` \n",
    "5. Set `self.conv.weight` to be `torch.nn.Parameters(weight)`\n",
    "6. In the forward function, calculate the output of the convolutional layer using `self.conv(x)` \n",
    "7. Run the output through a relu activation \n",
    "9. Return the output, and the value before activation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional layer (sees 32x32x3 image tensor)\n",
    "self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "# convolutional layer (sees 16x16x16 tensor)\n",
    "self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "# convolutional layer (sees 8x8x32 tensor)\n",
    "self.conv3 = nn.Conv2d(32, 64, 3, padding=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layers\n",
    "\n",
    "* Located between convolution layer\n",
    "* Reduce extra dimensions \n",
    "* Max pooling layer: Given a stack of feature maps returns the greatest value in each feature map\n",
    "    * Define a window size and stride (eg. Window 2X2, Stride: 2)\n",
    "    * Start with the top left corner window \n",
    "    * Take the maximum value in the window \n",
    "    * Continue for all features \n",
    "    * Finally, the final width and height are half of the previous convolutional layer. \n",
    "    \n",
    "\n",
    "* Average pooling layer: Chooses an average pixel values in a given window size \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inside init: \n",
    "self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "\n",
    "# Inside forward:\n",
    "x = self.pool(F.relu(self.conv1(x)))\n",
    "x = self.pool(F.relu(self.conv2(x)))\n",
    "x = self.pool(F.relu(self.conv3(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "\n",
    "In addition to simple convolutional and pooling layers we can also add batch normalization layers to our model. \n",
    "\n",
    "Batch normalization helps the model generalize and speeds up training by providing more variance for certain layers which makes the job of learning for the later layers easier. \n",
    "\n",
    "Batch norm also has a regularization effect, similiar to dropout batch norm adds some noice to each hidden layer's activation but the difference is batch norm adds noise because of the scaling by standard deviation. However this is not the purpose of batch norm. \n",
    "\n",
    "Note that with dropout by using a larger mini batch size you're also reducing a noise, which means that your accuracy will eventually increase. \n",
    "\n",
    "\n",
    "Documentation: https://pytorch.org/docs/stable/nn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init function: \n",
    "self.batch_norm = nn.BatchNorm2d(16)  # change 16 based on the layers number\n",
    "\n",
    "# Forward Function\n",
    "x = self.batch_norm(self.pool(F.relu(self.conv1(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Notes\n",
    "\n",
    "1. Lesson 5.35: To show an image, it is important to first convert the image into a numpy image.  \n",
    "1. When defining a network, don't forget to include the linear transformations. \n",
    "* [Wavenet model](https://deepmind.com/blog/wavenet-generative-model-raw-audio/): A CNN application, taking wavefroms recorded from humans used to generate an AI similiar to humans."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
